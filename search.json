[{"title":"Hello World","url":"/2025/11/14/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"},{"title":"Ollama 未授权访问漏洞 CNVD-2025-04094","url":"/2025/07/08/Ollama-未授权访问漏洞-CNVD-2025-04094/","content":"# Ollama 未授权访问漏洞 CNVD-2025-04094\n\n## 漏洞描述\n\nOllama 是一个本地私有化部署大语言模型（LLM，如 DeepSeek 等）的运行环境和平台，简化了大语言模型在本地的部署、运行和管理过程，具有简化部署、轻量级可扩展、API 支持、跨平台等特点，在 AI 领域得到了较为广泛的应用。\n\nOllama 存在未授权访问漏洞。由于 Ollama 默认未设置身份验证和访问控制功能，未经授权的攻击者可在远程条件下调用 Ollama 服务接口，执行包括但不限于敏感模型资产窃取、虚假信息投喂、模型计算资源滥用和拒绝服务、系统配置篡改和扩大利用等恶意操作。\n\n参考链接：\n\n- https://www.cnvd.org.cn/flaw/show/CNVD-2025-04094\n\n## 漏洞影响\n\n```\n未设置身份验证和访问控制功能且暴露在公共互联网上的 Ollama 易受此漏洞攻击影响\n```\n\n## 环境搭建\n\ndocker-compose.yml\n\n```\nservices:\n  ollama:\n    image: ollama/ollama:0.3.14\n    container_name: ollama\n    volumes:\n      - ollama:/root/.ollama\n    ports:\n      - \"11434:11434\"\n\nvolumes:\n  ollama:\n```\n\n执行如下命令启动 Ollama 0.3.14 服务:\n\n```\ndocker compose up -d\n```\n\n环境启动后，访问 `http://your-ip:11434/`，此时 Ollma 0.3.14 已经成功运行。\n\n\n## 漏洞复现\n\nOllama 公开了多个执行各种操作的 [API endpoints](https://github.com/ollama/ollama/blob/main/docs/api.md)：\n\n\n 通过 `/api/tags` 列出所有模型：\n\n```\nhttp://your-ip:11434/api/tags\n```\n\n## 漏洞修复\n\n- 限制公网访问：避免直接将 Ollama 服务端口（默认 11434）暴露在公网，仅允许内网或通过 VPN 访问。\n- 配置网络访问控制：通过云安全组、防火墙等手段限制对 Ollama 服务端口的访问来源，仅允许可信的源 IP 地址连接。\n- 启用身份认证保护：通过反向代理（如 Nginx）启用 HTTP Basic Authentication 或基于 OAuth 的认证机制。","categories":["baseTest"]},{"title":"CNN","url":"/2024/06/14/CNN/","content":"import torch\nimport torch.nn as nn\nimport torchvision \nimport torch.utils.data as Data\n \ntorch.manual_seed(1)  # 设置随机种子, 用于复现\n \n# 超参数\nEPOCH = 1       # 前向后向传播迭代次数\nLR = 0.001      # 学习率 learning rate \nBATCH_SIZE = 50 # 批量训练时候一次送入数据的size\nDOWNLOAD_MNIST = True \n \n# 下载mnist手写数据集\n# 训练集\ntrain_data = torchvision.datasets.MNIST(  \n    root = './MNIST/',                      \n    train = True,                            \n    transform = torchvision.transforms.ToTensor(),                                                \n    download=DOWNLOAD_MNIST \n)\n \n# 测试集\ntest_data = torchvision.datasets.MNIST(root='./MNIST/', train=False)  # train设置为False表示获取测试集\n \n# 一个批训练 50个样本, 1 channel通道, 图片尺寸 28x28 size:(50, 1, 28, 28)\ntrain_loader = Data.DataLoader(\n    dataset = train_data,\n    batch_size=BATCH_SIZE,\n    shuffle=True\n) \n#  测试数据预处理；只测试前2000个\ntest_x = torch.unsqueeze(test_data.data,dim=1).float()[:2000] / 255.0\n# shape from (2000, 28, 28) to (2000, 1, 28, 28)\ntest_y = test_data.targets[:2000]\n \nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN,self).__init__()\n \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(                      # 输入的图片 （1，28，28）\n                in_channels=1,\n                out_channels=16,            # 经过一个卷积层之后 （16,28,28）\n                kernel_size=5,\n                stride=1,                    # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1\n                padding=2\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)      # 经过池化层处理，维度为（16,14,14）\n        )\n \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(                         # 输入（16,14,14）\n                in_channels=16,\n                out_channels=32,\n                kernel_size=5,\n                stride=1,\n                padding=2\n            ),                                 # 输出（32,14,14）\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)        # 输出（32,7,7）\n        )\n \n        self.out = nn.Linear(32*7*7,10)\n \n    def forward(self, x):\n        x = self.conv1(x)                     #（batch_size,16,14,14）\n        x = self.conv2(x)                     # 输出（batch_size,32,7,7）\n        x = x.view(x.size(0),-1)              # (batch_size,32*7*7)\n        out = self.out(x)                     # (batch_size,10)\n        return out\n \ncnn = CNN()\noptimizer = torch.optim.Adam(cnn.parameters(),lr=LR) # 定义优化器\nloss_func = nn.CrossEntropyLoss() # 定义损失函数\n \nfor epoch in range(EPOCH):\n \n    for step,(batch_x,batch_y) in enumerate(train_loader):\n        pred_y = cnn(batch_x)\n        loss = loss_func(pred_y,batch_y)\n        optimizer.zero_grad() # 清空上一层梯度\n        loss.backward() # 反向传播\n        optimizer.step() # 更新优化器的学习率，一般按照epoch为单位进行更新\n \n        if step % 50 == 0:\n            test_output = cnn(test_x)\n            pred_y = torch.max(test_output, 1)[1].numpy()  # torch.max(test_out,1)返回的是test_out中每一行最大的数)\n                                                                # 返回的形式为torch.return_types.max(\n                                                                #           values=tensor([0.7000, 0.9000]),\n                                                                #           indices=tensor([2, 2]))\n                                                                # 后面的[1]代表获取indices\n            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n \n \n# 打印前十个测试结果和真实结果进行对比\ntest_output = cnn(test_x[:10])\npred_y = torch.max(test_output, 1)[1].numpy()\nprint(pred_y, 'prediction number')\nprint(test_y[:10].numpy(), 'real number')","categories":["featTest"]}]